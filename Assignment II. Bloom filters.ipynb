{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloom Filters\n",
    "\n",
    "## Task 1\n",
    "***Give an overview of the types of operations that a Bloom filter supports, and where Bloom filters might be useful.***\n",
    "\n",
    "Bloom filter is a probabilistic data structure that is used to test whether an element is in the hash table.\n",
    "\n",
    "Operations that Bloom filter supports:\n",
    "1. ***Element look-up***<br/>\n",
    "    **a.** If the searched element is **not** in the list, the filter will return the definite answer. The look-up complexity is always $O(1)$, which is much faster than an unsuccessful check of an element in open-addressing $O(\\frac{1}{1 - \\alpha})$ or chained hash tables $O(1 + \\alpha)$ where $\\alpha$ is the load factor (number of elements expected to be inserted or are already in the list and the number of cells in the hash table.<br/>\n",
    "    **b.** If element is in the list, we might encounter false positives when the filter thinks the element is there but actually its hash footprint is created by other elements. Runtime still always take constant time.<br/>\n",
    "\n",
    "2. ***Insertion***<br/>\n",
    "    **a.** An incoming element is hashed using k hash functions. Then we perform [1 **OR** with the values in the positions of the values the hash functions produced for the element]. <br/>\n",
    "    \n",
    "3. ***Deletion***<br/>\n",
    "    **a.** Original Bloom filter does not support deletion but we can enable deletion by adding counting at each hash table cell. Instead of storing 0 or 1 bits, we can make it a byte-array and add 1 every time the hash produces the cell position as value. \n",
    "    \n",
    "    \n",
    "    \n",
    "Bloom filters are an efficient way to filter queries when accessing information in large hash tables. For example, a website that stores logins of users could run the user's input login through a Bloom filter to determine whether such user even exists in a very short time. If it does not, we can return an error in a constant time because we don't have a load factor that would affect the lookup time. If the element probably exist, then it is worth spending time to search for it in the actual hash table and check the password it comes with.<br/>\n",
    "   \n",
    "## Task 2\n",
    "***Implement a Bloom filter.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import math\n",
    "\n",
    "class BloomFilter:\n",
    "# Private instances\n",
    "    __hash_params = []\n",
    "    __elem_cnt = 0\n",
    "    __bit_cnt = 0\n",
    "    \n",
    "    def __generate_hash_f(self):\n",
    "        self.__generate_large_prime_num()\n",
    "        p = self.__prime_base\n",
    "        for i in range(self.__num_hash_f):\n",
    "            self.__hash_params.append((randint(1, p - 1), randint(0, p - 1)))\n",
    "        \n",
    "    def __hash(self, elem):\n",
    "        hash_vals = []\n",
    "        p = self.__prime_base\n",
    "        \n",
    "        for params in self.__hash_params:\n",
    "            (a, b) = params\n",
    "            hash_value = ((a * elem + b) % p) % self.__arr_cp\n",
    "            hash_vals.append(hash_value)\n",
    "            \n",
    "        return hash_vals\n",
    "    \n",
    "    def __generate_large_prime_num(self):\n",
    "        self.__prime_base = 274876858367 # GENERATE PROPERLY, DUUUUDE\n",
    "    \n",
    "    \n",
    "# Formatting\n",
    "    def __str__(self):\n",
    "        out = '\\n\\033[1mBitmap\\033[0m\\n'\n",
    "        out += ' '.join(map(lambda x: str(x), self.__hash_map))\n",
    "        out += '\\n\\033[1mSome statistics\\033[0m'\n",
    "        out += '\\nBitmap capacity: ' + str(self.__arr_cp)\n",
    "        out += '\\nHash functions used: ' + str(self.__num_hash_f)\n",
    "        out += '\\nBit count: ' + str(self.__bit_cnt)\n",
    "        out += '\\nElement count: ' + str(self.__elem_cnt)\n",
    "        return out\n",
    "    \n",
    "        \n",
    "# Public instances\n",
    "    def __init__(self, arr_cp, fp_rate=0.01, num_hash_f=0):\n",
    "        self.__arr_cp = arr_cp\n",
    "        self.__hash_map = [0] * arr_cp\n",
    "        \n",
    "        if num_hash_f != 0:\n",
    "            self.__num_hash_f = num_hash_f\n",
    "        else:\n",
    "            self.__num_hash_f = math.ceil(-math.log(fp_rate))\n",
    "\n",
    "        self.__generate_hash_f()\n",
    "        \n",
    "    def add(self, elem):\n",
    "        if self.search(elem) == \"not in list\":\n",
    "            for idx in self.__hash(elem):\n",
    "                self.__hash_map[idx] = 1\n",
    "            self.__elem_cnt += 1\n",
    "            self.__bit_cnt = sum(self.__hash_map)\n",
    "    \n",
    "    def search(self, elem):\n",
    "        maybe_in_list = True\n",
    "        for idx in self.__hash(elem):\n",
    "            if self.__hash_map[idx] != 1:\n",
    "                maybe_in_list = False\n",
    "                \n",
    "        if maybe_in_list:\n",
    "            return \"maybe in list\"\n",
    "        return \"not in list\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "**Containers**:\n",
    "- hash_params - tuples of a and b coefficients for universal hash functions\n",
    "- hash_map - byte-array storing the key counters\n",
    "\n",
    "**Size**:\n",
    "- arr_cp - capacity of the hash table\n",
    "- arr_sz - current load level (number of inserted elements)\n",
    "- num_hash_f - number of hash functions\n",
    "\n",
    "**Counters**:\n",
    "- elem_cnt - count of inserted elements to resize when overfilled\n",
    "- bit_cnt - count of number of bits in the hash map\n",
    "\n",
    "**Constants**:\n",
    "- prime_base - the value of p for transforming $U \\to Z_p \\to Z_{arr\\_cp}$\n",
    "\n",
    "### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mBitmap\u001b[0m\n",
      "1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      "\u001b[1mSome statistics\u001b[0m\n",
      "Bitmap capacity: 100\n",
      "Hash functions used: 5\n",
      "Bit count: 27\n",
      "Element count: 6\n"
     ]
    }
   ],
   "source": [
    "bloom_filter = BloomFilter(arr_cp=100)\n",
    "bloom_filter.add(56)\n",
    "bloom_filter.add(54)\n",
    "bloom_filter.add(71)\n",
    "bloom_filter.add(91)\n",
    "bloom_filter.add(82)\n",
    "bloom_filter.add(49)\n",
    "bloom_filter.add(82)\n",
    "print(bloom_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "***Give a description of the hash functions that your implementation uses.***\n",
    "\n",
    "I generate hash functions from the universal set of hash functions to ensure that they will generate values uniformly on a restricted domain. This would mean that for two different values $x, y ∈ U, x \\neq y$, the probability that $h(x) = h(y) ∈ Z_{arr\\_cp}$ would be less or equal to $\\frac{1}{arr\\_cp}$.\n",
    "\n",
    "The reason I use a subset of universal hash functions is to reduce the rate of false positives by not \"overfilling\" some particular cells in the hash map. If we reuse the same set of cells too often, when we search for a new value, its hash will likely fall into those cells and return a false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "***Provide an analysis of how your implementation scales in terms of:***<br/>\n",
    "Let's use the following notation:\n",
    "- $k$ is the number of hash functions the Bloom filter uses\n",
    "- $m$ is the total number of bits allocated to store the elements\n",
    "- $n$ is the number of elements inserted into the hash table\n",
    "- $p_{fp}$ is the probability of a false-positive lookup result\n",
    "- $X$ is the number of bits set to one\n",
    "\n",
    "    *1) memory size as a function of the false positive rate*<br/>\n",
    "    Approximation of false positive rate:\n",
    "    $$ (1 - e^{-\\frac{kn}{m}})^k = p_{fp} $$\n",
    "    $$ 1 - e^{-\\frac{kn}{m}} = \\sqrt[k]{p_{fp}} $$\n",
    "    $$ (e^{-kn})^{1/m} = 1 - \\sqrt[k]{p_{fp}} $$\n",
    "    $$ \\dfrac{1}{m} = log_{e^{-kn}}(1 - \\sqrt[k]{p_{fp}}) $$\n",
    "    $$ m = log_{1 - \\sqrt[k]{p_{fp}}}(e^{-kn}) $$\n",
    "    $$ m = log_{1 - \\sqrt[k]{p_{fp}}}(e^{⌈ln(p_{fp})⌉n}) $$\n",
    "    $$ m = \\Theta(log_{1 - \\sqrt[k]{p_{fp}}}(e^{n}logp_{fp})) $$\n",
    "    \n",
    "   *2) memory size as a function of the number of items stored*<br/>\n",
    "    Using the formula for estimated number of inserted items derived in Swamidass & Baldi (2007):\n",
    "    $$ n^* = -\\dfrac{m}{k}ln(1 - \\dfrac{X}{m}) $$\n",
    "    $$ m = -\\dfrac{kn^*}{ln(1 - \\frac{X}{m})}  $$\n",
    "    $$ m = \\Theta(-\\dfrac{kn^*}{ln(1 - \\frac{X}{m})})  $$\n",
    "    \n",
    "   *3) access time as a function of the false positive rate*<br/>\n",
    "   Access time depends on the number of hash function we use:\n",
    "    $$ k = ⌈-ln(p_{fp})⌉ $$\n",
    "    $$ k = \\Theta(-logp_{fp}) $$\n",
    "    \n",
    "   *4) access time as a function of the number of items stored*<br/>\n",
    "   Access time does not depend on the number of items stored because in any case we need to check $k$ cells.\n",
    "    $$ k = \\Theta(1 + 0n) $$\n",
    "    \n",
    "## Task 5\n",
    "***Produce a plot to show that your implementation’s false positive rate matches the theoretically expected rate.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFor theoretical p_fp, we will generate values for m from p_fp and\\nthen swap the axes to show the rate of growth for p_fp\\n'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### False positive rate and memory size\n",
    "NUM_BL_FILT = 1 # use several bl. filters per capacity to account for error\n",
    "MIN_ARR_CP = 20\n",
    "MAX_ARR_CP = 22\n",
    "NUM_ELEM = 20\n",
    "U = list(range(10^6)) # universe of possible keys\n",
    "\n",
    "'''\n",
    "Bloom filters initialization\n",
    "'''\n",
    "num_cps = MAX_ARR_CP - MIN_ARR_CP + 1\n",
    "\n",
    "# matrix of size num_capacities * NUM_BL_FILT * NUM_ELEM\n",
    "# to store actual elements in the set\n",
    "hash_map = [[]] * num_cps\n",
    "\n",
    "# matrix of size num_capacities * NUM_BL_FILT to store all bloom filters\n",
    "bl_filts = [[]] * num_cps\n",
    "\n",
    "for row in range(num_cps):\n",
    "    for _ in range(NUM_BL_FILT):\n",
    "        bl_filts[row].append(BloomFilter(it + MIN_ARR_CP))\n",
    "        \n",
    "        \n",
    "'''\n",
    "Random items insertion\n",
    "'''\n",
    "for row in range(num_cps):\n",
    "    for bl_id in range(NUM_BL_FILT):\n",
    "        for _ in range(NUM_ELEM):\n",
    "            bl_filts[row][bl_id].add(U[randint(1, len(U) - 1)])\n",
    "            print(\"added\")\n",
    "        \n",
    "'''\n",
    "Items lookup false positives\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "For theoretical p_fp, we will generate values for m from p_fp and\n",
    "then swap the axes to show the rate of growth for p_fp\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
