{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "## Genetic heritage:\n",
    "The following 7 strings were generated by taking an existing string and with a small probability either inserting a new character, deleting an existing character, or changing to a new character randomly. This created two child strings, each of these strings with a single character changed from their parent. And from the two child strings, four grandchild strings were created, two from each child. The 4 grandchild strings also have a single character changed from their parents. As result, we got 7 strings but unfortunately the order of the strings has been lost.\n",
    "\n",
    "(0, 'CAGCGGGTGCGTAATTTGGAGAAGTTATTCTGCAACGAAATCAATCCTGTTTCGTTAGCTTACGGACTACGACGAGAGGGTACTTCCCTGATATAGTCAC')<br/>\n",
    "(1, 'CAAGTCGGGCGTATTGGAGAATATTTAAATCGGAAGATCATGTTACTATGCGTTAGCTCACGGACTGAAGAGGATTCTCTCTTAATGCAA')<br/>\n",
    "(2, 'CATGGGTGCGTCGATTTTGGCAGTAAAGTGGAATCGTCAGATATCAATCCTGTTTCGTAGAAAGGAGCTACCTAGAGAGGATTACTCTCACATAGTA')<br/>\n",
    "(3, 'CAAGTCCGCGATAAATTGGAATATTTGTCAATCGGAATAGTCAACTTAGCTGGCGTTAGCTTTACGACTGACAGAGAGAAACCTGTCCATCACACA')<br/>\n",
    "(4, 'CAAGTCCGGCGTAATTGGAGAATATTTTGCAATCGGAAGATCAATCTTGTTAGCGTTAGCTTACGACTGACGAGAGGGATACTCTCTCTAATACAA')<br/>\n",
    "(5, 'CACGGGCTCCGCAATTTTGGGTCAAGTTGCATATCAGTCATCGACAATCAAACACTGTTTTGCGGTAGATAAGATACGACTGAGAGAGGACGTTCGCTCGAATATAGTTAC')<br/>\n",
    "(6, 'CACGGGTCCGTCAATTTTGGAGTAAGTTGATATCGTCACGAAATCAATCCTGTTTCGGTAGTATAGGACTACGACGAGAGAGGACGTTCCTCTGATATAGTTAC')<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Write python code to give the length of the longest common subsequence for two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lcs(str_1, str_2):\n",
    "    m = len(str_1)\n",
    "    n = len(str_2)\n",
    "    lcs_len = []\n",
    "    \n",
    "    for i in range(m):\n",
    "        lcs_len.append([])\n",
    "        for j in range(n):\n",
    "            lcs_len[i].append(0)\n",
    "    \n",
    "    for i in range(1, m):\n",
    "        for j in range(1, n):\n",
    "            if str_1[i] == str_2[j]:\n",
    "                lcs_len[i][j] = lcs_len[i - 1][j - 1] + 1 # subproblem's LCS + 1\n",
    "            elif lcs_len[i - 1][j] > lcs_len[i][j - 1]:\n",
    "                lcs_len[i][j] = lcs_len[i - 1][j] # subproblem's LCS\n",
    "            else:\n",
    "                lcs_len[i][j] = lcs_len[i][j - 1] # subproblem's LCS\n",
    "    \n",
    "    return lcs_len[-1][-1] + 1\n",
    "\n",
    "str_1 = \"CAGCGGGTGCGTAATTTGGAGAAGTTATTCTGCAACGAAATCAATCCTGTTTCGTTAGCTTACGGACTACGACGAGAGGGTACTTCCCTGATATAGTCAC\"\n",
    "str_2 = \"CAAGTCCGGCGTAATTGGAGAATATTTTGCAATCGGAAGATCAATCTTGTTAGCGTTAGCTTACGACTGACGAGAGGGATACTCTCTCTAATACAA\"\n",
    "lcs(str_1, str_2)\n",
    "lcs(\"abfeb\", \"abcfeabee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Generate the table of the lengths of the longest common subsequences for every pair of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100, 74, 76, 73, 82, 84, 91], [74, 90, 67, 72, 80, 70, 71], [76, 67, 97, 65, 69, 81, 84], [73, 72, 65, 96, 81, 71, 69], [82, 80, 69, 81, 96, 74, 75], [84, 70, 81, 71, 74, 111, 97], [91, 71, 84, 69, 75, 97, 104]]\n"
     ]
    }
   ],
   "source": [
    "seqs = [\n",
    "    (0, 'CAGCGGGTGCGTAATTTGGAGAAGTTATTCTGCAACGAAATCAATCCTGTTTCGTTAGCTTACGGACTACGACGAGAGGGTACTTCCCTGATATAGTCAC'),\n",
    "    (1, 'CAAGTCGGGCGTATTGGAGAATATTTAAATCGGAAGATCATGTTACTATGCGTTAGCTCACGGACTGAAGAGGATTCTCTCTTAATGCAA'),\n",
    "    (2, 'CATGGGTGCGTCGATTTTGGCAGTAAAGTGGAATCGTCAGATATCAATCCTGTTTCGTAGAAAGGAGCTACCTAGAGAGGATTACTCTCACATAGTA'),\n",
    "    (3, 'CAAGTCCGCGATAAATTGGAATATTTGTCAATCGGAATAGTCAACTTAGCTGGCGTTAGCTTTACGACTGACAGAGAGAAACCTGTCCATCACACA'),\n",
    "    (4, 'CAAGTCCGGCGTAATTGGAGAATATTTTGCAATCGGAAGATCAATCTTGTTAGCGTTAGCTTACGACTGACGAGAGGGATACTCTCTCTAATACAA'),\n",
    "    (5, 'CACGGGCTCCGCAATTTTGGGTCAAGTTGCATATCAGTCATCGACAATCAAACACTGTTTTGCGGTAGATAAGATACGACTGAGAGAGGACGTTCGCTCGAATATAGTTAC'),\n",
    "    (6, 'CACGGGTCCGTCAATTTTGGAGTAAGTTGATATCGTCACGAAATCAATCCTGTTTCGGTAGTATAGGACTACGACGAGAGAGGACGTTCCTCTGATATAGTTAC')\n",
    "]\n",
    "\n",
    "seq_ct = len(seqs)\n",
    "dists = []\n",
    "\n",
    "for i in range(seq_ct):\n",
    "    dists.append([])\n",
    "    for j in range(seq_ct):\n",
    "        lcs_len = lcs(seqs[i][1], seqs[j][1])\n",
    "        dists[i].append(lcs_len)\n",
    "        \n",
    "print(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>82</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>90</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>67</td>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>96</td>\n",
       "      <td>81</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>69</td>\n",
       "      <td>81</td>\n",
       "      <td>96</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84</td>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>111</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>91</td>\n",
       "      <td>71</td>\n",
       "      <td>84</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "      <td>97</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4    5    6\n",
       "0  100  74  76  73  82   84   91\n",
       "1   74  90  67  72  80   70   71\n",
       "2   76  67  97  65  69   81   84\n",
       "3   73  72  65  96  81   71   69\n",
       "4   82  80  69  81  96   74   75\n",
       "5   84  70  81  71  74  111   97\n",
       "6   91  71  84  69  75   97  104"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dists_dct = {}\n",
    "for i in range(len(dists)):\n",
    "    dists_dct[i] = dists[i]\n",
    "\n",
    "df = pd.DataFrame(dists_dct)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fig. 1-1: Table of lengths of common subsequences (LCS) of all sequence pairs. Main diagonal (up left to down right) contains the lengths of original sequences, since they are LCS of the same string.***\n",
    "\n",
    "Seeing numbers might be irrelevant, so instead we could take a look at what fraction of bases is retained in all pairs of sequences (by dividing by the actual sequence length). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.74</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690722</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.630631</td>\n",
       "      <td>0.682692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.639640</td>\n",
       "      <td>0.663462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.711340</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.721154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6\n",
       "0  1.00  0.822222  0.783505  0.760417  0.854167  0.756757  0.875000\n",
       "1  0.74  1.000000  0.690722  0.750000  0.833333  0.630631  0.682692\n",
       "2  0.76  0.744444  1.000000  0.677083  0.718750  0.729730  0.807692\n",
       "3  0.73  0.800000  0.670103  1.000000  0.843750  0.639640  0.663462\n",
       "4  0.82  0.888889  0.711340  0.843750  1.000000  0.666667  0.721154\n",
       "5  0.84  0.777778  0.835052  0.739583  0.770833  1.000000  0.932692\n",
       "6  0.91  0.788889  0.865979  0.718750  0.781250  0.873874  1.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac_dct = {}\n",
    "for i in range(len(dists)):\n",
    "    frac_dct[i] = list(map(lambda elem: elem / max(dists[i]), dists[i]))\n",
    "\n",
    "df = pd.DataFrame(frac_dct)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fig. 1-2: Table of fractions of retained bases compared to the gene number in the column. Note: this table is non-symmetrical.***\n",
    "\n",
    "To determine which sequences are related, we will scan through column-wise and see which two (one parent and one sister; one parent and one grandparent; two children) have the highest retainment rate compared to the column number sequence. We then will \"untangle\" these relationships into a binary tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "Manually examine the table, and infer the relationships between strings.\n",
    "\n",
    "$$$$\n",
    "<img src=\"img/seq-relationships.png\" width=\"300\">\n",
    "\n",
    "***Fig. 2-1: Relationships between sequences. Solid lines indicate the relationship with the highest base-retainment rate (strong relationship). Dotted line shows weaker connections (2nd or 3rd highest base-retainment).***\n",
    "\n",
    "$$$$\n",
    "<img src=\"img/seq-tree-2.png\" width=\"300\">\n",
    "\n",
    "***Fig. 2-2: Tree built on the relationships above, putting strongest relationships in a parent-child relationship in a tree and 2nd strongest as either parent-child or 2 generations apart or sisters.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "How would you estimate the probabilities of mutation, insertions and deletions? (There might not be enough data to give meaningful estimates, but at least have a clear idea of the approach.)\n",
    "\n",
    "To estimate the probabilities of these operations, we can guess the set and order of the operations that happened to tranform one sequence into another. We will assume that nature will choose the shortest path to modify the sequences and not have infinite operation loops (e.g. \"abc\" → *insertion at 2* → \"abbc\" → *mutation at 1* → \"aabc\" → *deletion at 0* → \"abc\"). Then, using the Wagner–Fischer algorithm, we can find what operations were involved in a sequence transformation.\n",
    "\n",
    "Having gathered the amounts of each operation and the length of sequences, we can then approximate the probabilities by finding the mean modification percentage over different lengths and sequences. The more data we have, the closer the estimated probability will align to the actual probability of an operation because of the regression to the mean property of probability distributions of these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutations: 1 Deletions: 1 Insertions: 0\n"
     ]
    }
   ],
   "source": [
    "def edit_dist(str_1, str_2):\n",
    "    s_1 = \" \" + str_1\n",
    "    s_2 = \" \" + str_2\n",
    "    m = len(s_1)\n",
    "    n = len(s_2)\n",
    "    dists = [] # min operations to get from suffix str_1[:i] to str_2[:j], init to 0\n",
    "    \n",
    "    # init \n",
    "    for i in range(m): \n",
    "        if i == 0:\n",
    "            dists.append(list(range(n)))\n",
    "        else:\n",
    "            dists.append([i] + list(map(lambda x: 0, range(1, n))))\n",
    "    \n",
    "    for i in range(1, m):\n",
    "        for j in range(1, n):\n",
    "            if s_1[i] == s_2[j]:\n",
    "                dists[i][j] = dists[i - 1][j - 1]\n",
    "            else:\n",
    "                dists[i][j] = min(\n",
    "                    dists[i - 1][j - 1], # mutation\n",
    "                    dists[i - 1][j], # deletion\n",
    "                    dists[i][j - 1] # insertion\n",
    "                ) + 1\n",
    "    \n",
    "    return dists\n",
    "\n",
    "def backtrack_ops(dists):\n",
    "    mut_ct = del_ct = ins_ct = 0\n",
    "    \n",
    "    i, j = len(dists) - 1, len(dists[0]) - 1\n",
    "    while i > 0 or j > 0:\n",
    "        cur_min = dists[i][j] # to store best next step\n",
    "        opt_coor = (i, j)\n",
    "        \n",
    "        if i - 1 >= 0 and j - 1 >= 0 and cur_min >= dists[i - 1][j - 1]:\n",
    "            cur_min = dists[i - 1][j - 1]\n",
    "            opt_coor = (i - 1, j - 1)\n",
    "            if dists[i - 1][j - 1] != dists[i][j]:\n",
    "                mut_ct += 1\n",
    "        else:\n",
    "            if i - 1 >= 0 and cur_min >= dists[i - 1][j]:\n",
    "                cur_min = dists[i - 1][j]\n",
    "                opt_coor = (i - 1, j)\n",
    "                del_ct += 1\n",
    "            if j - 1 >= 0 and cur_min >= dists[i][j - 1]:\n",
    "                cur_min = dists[i][j - 1]\n",
    "                opt_coor = (i, j - 1)\n",
    "                ins_ct += 1\n",
    "        (i, j) = opt_coor\n",
    "                \n",
    "    return mut_ct, del_ct, ins_ct\n",
    "\n",
    "    \n",
    "dists = edit_dist(\"aaaba\", \"abaa\")\n",
    "ops = backtrack_ops(dists)\n",
    "print(\"Mutations:\", ops[0], \"Deletions:\", ops[1], \"Insertions:\", ops[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutation probability: 23.78% \n",
      "Deletion probability: 3.20% \n",
      "Insertion probability: 3.59%\n"
     ]
    }
   ],
   "source": [
    "P_mut = P_del = P_ins = 0\n",
    "\n",
    "for i in range(seq_ct):\n",
    "    for j in range(seq_ct):\n",
    "        dists = edit_dist(seqs[i][1], seqs[j][1])\n",
    "        ops = backtrack_ops(dists)\n",
    "        \n",
    "        factor = float(len(seqs[i][1])) * seq_ct**2\n",
    "        P_mut += ops[0] / factor\n",
    "        P_del += ops[1] / factor\n",
    "        P_ins += ops[2] / factor\n",
    "        \n",
    "print(\"Mutation probability:\", str(P_mut*100)[:5] + \"%\",\n",
    "      \"\\nDeletion probability:\", str(P_del*100)[:4] + \"%\",\n",
    "      \"\\nInsertion probability:\", str(P_ins*100)[:4] + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "Can you devise an algorithm in the general case which might be able to infer such a tree of relationships? Give any strengths or weaknesses of your suggested algorithm.\n",
    "\n",
    "To do so, we cant calculate the number of mutations, deletions, and insertions for each pair for sequences and check if the percentages of those operations compared the original sequence are almost equal to the probabilities above. Then, these sequences would likely be of 1st order relationship. If the percentages happen to be in the order of squares of the probabilities above, then the sequences most likely would be of 2nd order relationship (and so forth, for all pairs).\n",
    "\n",
    "Then, assuming that one sequence can only have one parent (e.g. in asexual reproduction), we can build a tree by looking at which node has highest *connectivity* $\\sum_{i=1}^n \\dfrac{count_{ord}}{ord}$, where $n$ is the number of sequences, $ord$ is the order of relationship (1st being the closest) and $count_{ord}$ is the number of relationships of order $ord$.\n",
    "\n",
    "The universal ancestor would have the highest connectivity because $ord$ is at most the height of the tree. For all other nodes, $height(tree) \\leq max(ord(node_i, node_j), j = 1 \\to n) \\leq 2 height(tree)$. Then, the summation terms would be smaller.\n",
    "\n",
    "Next step is to sort the nodes in an array based on their connectivity in the descending order. Lastly, using the greedy approach, we keep track of the order of the current node compared to the first node in the array, and whenever the order increases, we will evaluate the node's ***edit_dist*** with the nodes in the previous layers, and whichever is minimum, that one would be the parent of the current node. This cross-comparison will take $O((n)^2)$ time complexity as we go through the whole list, and for each element we compare $O(n)$ times to find its parent.\n",
    "\n",
    "For large amounts of data, this algorithm would be highly inefficient as it scales quadratically with the number of sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "Describe the complexity of your solution to identify related “genes” for this assignment. (Let M be the length of a gene, and N be the number of genes.)\n",
    "\n",
    "My solution is of $O(M^2N^2)$ time complexity because we scan through each pair of suffixes (M^2) of the each pair of words (N^2) and do a constant amount of comparisons at each step. Then, I spend $O(M)$ for backtracking the path taken in each pair and $O(MN^2)$ in total for all pairs. The space complexity is $O(M^2)$ for each pair of genes, and total space complexity is $O(M^2N^2)$ to store the matrices of number of operations to transform each suffix to another in each pair of sequences.\n",
    "\n",
    "The space complexity to this problem could be improved by storing only 2 rows in **edit_dist(str_1, str_2)** (current and previous row). Then, the exact operations can be derived from the following:\n",
    "1. When we insert a base, the LCS b/w original and modified string does not change, but the length increases by 1\n",
    "2. When we delete a base, the LCS drops by one, and the length drops by 1\n",
    "3. When we mutate a base, the LCS drops by one, and the length does not change\n",
    "\n",
    "Using these three conditions, we can infer the number of each operations by solving this system of equations:\n",
    "$$\n",
    "\\begin{cases}\n",
    "    len(seq_1) = len(seq_2) + I - D \\\\\n",
    "    LCS(seq_1, seq_2) = len(seq_1) - D - M \\\\\n",
    "    num_{ops} = I + D + M\n",
    "\\end{cases}\n",
    "$$\n",
    "where $I, D, M$ are the number of insertions, deletions, and mutations, respectively. $LCS(s_1, s_2)$ in this case gives the length of the longest common subsequence of two strings.\n",
    "\n",
    "\n",
    "Since this is a linear system of equations, we can easily express each of the unknowns:\n",
    "$$\n",
    "\\begin{cases}\n",
    "    I = len(seq_1) - len(seq_2) + D \\\\\n",
    "    D = len(seq_1) - LCS(seq_1, seq_2) - M \\\\\n",
    "    M = I + D - num_{ops}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    M = len(seq_1) - len(seq_2) + 2(len(seq_1) - LCS(seq_1, seq_2) - M) - num_{ops} \\\\\n",
    "    I = len(seq_1) - len(seq_2) + D \\\\\n",
    "    D = len(seq_1) - LCS(seq_1, seq_2) - M\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    M = len(seq_1) - \\dfrac{1}{3}len(seq_2) - \\dfrac{2}{3}LCS(seq_1, seq_2) - \\dfrac{1}{3}num_{ops} \\\\\n",
    "    D = \\dfrac{1}{3}len(seq_2) - \\dfrac{1}{3}LCS(seq_1, seq_2) + \\dfrac{1}{3}num_{ops}) \\\\\n",
    "    I = len(seq_1) - \\dfrac{2}{3}len(seq_2) - \\dfrac{1}{3}LCS(seq_1, seq_2) + \\dfrac{1}{3}num_{ops})\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Then, to calculate the number of each operation, we need only O(1) time complexity.\n",
    "\n",
    "This improved solution then needs:\n",
    "1. $O(M^2)$ time complexity to find the matrix of optimal transformations from each suffix of one string to each suffix of another. $O(M^2N^2)$ to find the optimal transformations for all pairs.\n",
    "2. $O(M)$ space complexity to store the current row and upper row at each step, $O(MN^2)$ for all pairs.\n",
    "3. $O(1)$ time complexity to determine the number of insertions, deletions, and mutations. $O(N^2)$ for all pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "Give differences between this assignment and inferring relationships in real gene sequences.\n",
    "\n",
    "In real life, whole genome sequences are ~3B long, so using Wagner-Fischer's algorithm to determine the relationship between two sequences would be very inefficient. There are methods more suitable for this, such as indexing (current state-of-art tool is Tabix) to efficientlyquery for certain parts of genomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography:\n",
    "1. Wikipedia contributors. (2018, February 6). Wagner–Fischer algorithm. In Wikipedia, The Free Encyclopedia. Retrieved 01:55, December 13, 2018, from https://en.wikipedia.org/w/index.php?title=Wagner%E2%80%93Fischer_algorithm&oldid=824346754\n",
    "2. Li, H. (2017, January 5). Tabix: Fast retrieval of sequence features from generic TAB-delimited files. Retrieved from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3042176/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***#algorithms***: I built upon Wagner-Fischer's algorithm to precisely calculate the amount of insertions, deletions, and mutations from the table of number of optimal operations and explained how such calculations could be improved in terms of time complexity.<br/>\n",
    "***#dataviz***: Presented explanatory figures and tables and provided descriptive captions for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
